a.time
a.time = cutoff.time[s]
a.time
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
while(a.time <= cutoff.time[s])
{
a.time = rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
}
a.time
cutoff.time[s]
a.time = a.time - cutoff.time[s]
a.time
data.cutoff
a.time
censor.squiggle[s] = ifelse(a.time < data.cutoff, 1, 0)
censor.squiggle[s]
time.squiggle[s]
data.cutoff
a.time
min(data.cutoff,a.time)
for(s in on.study.id)
{
a.time = cutoff.time[s]
while(a.time <= cutoff.time[s])
{
a.time = rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
}
a.time = a.time - cutoff.time[s]
censor.squiggle[s] = ifelse(a.time < data.cutoff, 1, 0)
time.squiggle[s] = time.squiggle[s] + min(data.cutoff,a.time)
}
time.squiggle
censor.squiggle
data.cutoff
data.cutoff
a.time
cutoff.time
cutoff.time[s]
cutoff.time[s]
cutoff.time[s]
censor.squiggle
cutoff.censor
data.cutoff
fit<-survfit(Surv(time.squiggle,censor.squiggle)~data$new_trt)
t = fit[1]$time
s = fit[1]$surv
t
s
plot(s)
plot(t)
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*sample-1),length(s)))
trt_group <-c(trt_group,rep(1,length(s)))
trt_group
class
control.temp = t[which(s <= 0.5)[1]]
control.temp
control.median[sample] = control.temp
control.events[sample] = sum(censor.squiggle[data$new_trt==0])
control.temp
t[which(s <= 0.5)[1]]
sample
d = coxph(Surv(time.squiggle,censor.squiggle)~data$new_trt)
summary(d)$coefficients[5]
pvalue[sample] = summary(d)$coefficients[5]
hazardratio[sample] = exp(as.numeric(d[1]))
events[sample] = sum(censor.squiggle)
lower.bound[sample] = exp(as.numeric(d[1]) - 1.96*sqrt(as.numeric(d[2])))
upper.bound[sample] = exp(as.numeric(d[1]) + 1.96*sqrt(as.numeric(d[2])))
treat.median
##############################################################################################################
##############################################################################################################
## Global Libraries/Packages
##############################################################################################################
##############################################################################################################
runPackages = function(pkg){
new.pkg = pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, library, character.only = TRUE)
}
packages = c("ggplot2", "grid", "shinythemes", "foreign", "reshape", "reshape2", "shiny", "devtools",
"gridExtra", "gtable", "stringr", "boot", "DT", "shinyjs","tidyverse","shinydashboard",
"dplyr", "foreach", "doParallel", "shinyBS", "Rcpp", "colorspace", "yaml","survival","msm",
"colourpicker", "data.table", "xtable", "scales", "htmltools", "tidyr", "wesanderson", "RColorBrewer")
runPackages(packages)
colors <- c("#E69F00", "#56B4E9","#000000" )
#### read the data ####
library(xlsx)
data = read.csv("~/Dropbox/FDA/code/toy_example.csv")
names(data) <- c('ind', 'TRT', 'CNSR','AVAL','STARTDT','ADT')
head(data)
## data is 168 by 6 matrix, with 141 not censored, 27 censored
trt="TRT";cnsr="CNSR";value="AVAL";start="STARTDT";end="ADT";times=c(6);data.cutoff=6;
nsamples=50;seed=42;trt_ind=1
set.seed(seed)
times=c(data.cutoff/2,data.cutoff)
data[[start]] = as.Date(data[[start]])
data[[end]] = as.Date(data[[end]])
## Censored survival data
subject <- as.factor(1:dim(data)[1])
years <- as.numeric((data[[end]] - data[[start]])/365)
data.time <- tibble(subject = as.factor(1:dim(data)[1]),
year = years,
censor = ifelse(data$CNSR,'Event','Censor'))
head(data.time)
plot.censor.event <- ggplot(data.time, aes(subject, year)) +
geom_bar(stat = "identity", width = 0.5) +
geom_point(data = data.time,
aes(subject, year, color = censor, shape = censor),
size = 1) +
coord_flip() +
theme_minimal() +
theme(legend.title = element_blank(),
legend.position = "bottom")
plot.censor.event
## distribution of censored
dist.censor <- ggplot(data.time, aes(x = year*365, fill = factor(censor))) +
geom_histogram(bins = 25, alpha = 0.6, position = "identity") +
scale_fill_manual(values = c("blue", "red"), labels = c("Censored", "Dead")) +
labs(x = "Days",
y = "Count")
dist.censor
diff = times-c(0,times[1:(length(times)-1)])
lam = rep(0.05,length(times) + 1)
beta = 0
on.study <- data[[end]][which(data[[cnsr]]==0)] > max(data[[end]])-90
on.study.id = (which(data[[cnsr]]==0))[on.study]
lower.bound = rep(NA,nsamples)
upper.bound = rep(NA,nsamples)
cutoff.time = data[[value]]
cutoff.censor = data[[cnsr]]
control.median = rep(NA,nsamples)
treat.median = rep(NA,nsamples)
difference = rep(NA,nsamples)
pvalue = rep(NA,nsamples)
hazardratio = rep(NA,nsamples)
control.events = rep(NA,nsamples)
treat.events = rep(NA,nsamples)
events = rep(NA,nsamples)
time_vals<- NULL
surv_vals<-NULL
class<-NULL
trt_group <- NULL
accept <- c()
trt_ind <- ifelse(is.numeric(data[[trt]][1]),as.numeric(as.character(trt_ind)),as.character(trt_ind))
data$new_trt<- ifelse(data[[trt]]==trt_ind,1,0)
temp_mat <- cbind(cutoff.time,cutoff.censor,data$new_trt)
current.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
runPackages = function(pkg){
new.pkg = pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, library, character.only = TRUE)
}
packages = c("ggplot2", "grid", "shinythemes", "foreign", "reshape", "reshape2", "shiny", "devtools",
"gridExtra", "gtable", "stringr", "boot", "DT", "shinyjs","tidyverse","shinydashboard",
"dplyr", "foreach", "doParallel", "shinyBS", "Rcpp", "colorspace", "yaml","survival","msm",
"colourpicker", "data.table", "xtable", "scales", "htmltools", "tidyr", "wesanderson", "RColorBrewer")
runPackages(packages)
colors <- c("#E69F00", "#56B4E9","#000000" )
log.like_new_test = function(vector,time,diff,beta,lambda)
{
test = (time < vector[1])
if(sum(test) > 0)
{
ch = sum(diff*lambda[1:length(test)]*test) + lambda[sum(test) + 1]*(vector[1] - time[sum(test)])
}else
{
ch = vector[1]*lambda[1]
}
vector[2]*(beta*vector[3] + log(lambda[sum(time < vector[1]) + 1])) - exp(beta*vector[3])*ch
}
##### Log-likelihood #####
log.likelihood = function(e_time,censors,lambda,beta,time,diff,treatment)
{
value = 0
for(i in 1:length(e_time))
value = value + log.like(e_time[i],censors[i],treatment[i],time,diff,beta,lambda)
value
}
log.likelihood_new = function(matrix,lambda,beta,time,diff)
{
sum(apply(matrix,1,log.like_new_test,time,diff,beta,lambda))
}
#### read the data ####
library(xlsx)
data = read.csv("~/Dropbox/FDA/code/toy_example.csv")
names(data) <- c('ind', 'TRT', 'CNSR','AVAL','STARTDT','ADT')
head(data)
## data is 168 by 6 matrix, with 141 not censored, 27 censored
trt="TRT";cnsr="CNSR";value="AVAL";start="STARTDT";end="ADT";times=c(6);data.cutoff=6;
nsamples=50;seed=42;trt_ind=1
set.seed(seed)
times=c(data.cutoff/2,data.cutoff)
data[[start]] = as.Date(data[[start]])
data[[end]] = as.Date(data[[end]])
## Censored survival data
subject <- as.factor(1:dim(data)[1])
years <- as.numeric((data[[end]] - data[[start]])/365)
data.time <- tibble(subject = as.factor(1:dim(data)[1]),
year = years,
censor = ifelse(data$CNSR,'Event','Censor'))
head(data.time)
plot.censor.event <- ggplot(data.time, aes(subject, year)) +
geom_bar(stat = "identity", width = 0.5) +
geom_point(data = data.time,
aes(subject, year, color = censor, shape = censor),
size = 1) +
coord_flip() +
theme_minimal() +
theme(legend.title = element_blank(),
legend.position = "bottom")
plot.censor.event
## distribution of censored
dist.censor <- ggplot(data.time, aes(x = year*365, fill = factor(censor))) +
geom_histogram(bins = 25, alpha = 0.6, position = "identity") +
scale_fill_manual(values = c("blue", "red"), labels = c("Censored", "Dead")) +
labs(x = "Days",
y = "Count")
dist.censor
diff = times-c(0,times[1:(length(times)-1)])
lam = rep(0.05,length(times) + 1)
beta = 0
on.study <- data[[end]][which(data[[cnsr]]==0)] > max(data[[end]])-90
on.study.id = (which(data[[cnsr]]==0))[on.study]
lower.bound = rep(NA,nsamples)
upper.bound = rep(NA,nsamples)
cutoff.time = data[[value]]
cutoff.censor = data[[cnsr]]
control.median = rep(NA,nsamples)
treat.median = rep(NA,nsamples)
difference = rep(NA,nsamples)
pvalue = rep(NA,nsamples)
hazardratio = rep(NA,nsamples)
control.events = rep(NA,nsamples)
treat.events = rep(NA,nsamples)
events = rep(NA,nsamples)
time_vals<- NULL
surv_vals<-NULL
class<-NULL
trt_group <- NULL
accept <- c()
trt_ind <- ifelse(is.numeric(data[[trt]][1]),as.numeric(as.character(trt_ind)),as.character(trt_ind))
data$new_trt<- ifelse(data[[trt]]==trt_ind,1,0)
temp_mat <- cbind(cutoff.time,cutoff.censor,data$new_trt)
current.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
sample = 1
message(paste("Running sample number",sample,"of",nsamples))
level = ifelse(sample==1,1000,500)
for(i in 1:level)
{
s = sample(c(1:length(lam)),1)
old = lam[s]
lam[s] = lam[s] + rnorm(1,mean=0,sd=0.05)
prop = 0
if(lam[s] > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop)
{
current.ll = propose.ll
accept = c(accept,1)
}else{
lam[s] = old
accept=c(accept,0)
}
old = beta
beta = beta + rnorm(1,mean=0,sd=0.1)
prop = 0
if(beta > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop){
current.ll = propose.ll
}else{
beta = old
}
}
accept
mean(accept)
old = beta
beta = beta + rnorm(1,mean=0,sd=0.1)
prop = 0
if(beta > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop){
current.ll = propose.ll
}else{
beta = old
}
{
s = sample(c(1:length(lam)),1)
old = lam[s]
lam[s] = lam[s] + rnorm(1,mean=0,sd=0.05)
prop = 0
if(lam[s] > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop)
{
current.ll = propose.ll
accept = c(accept,1)
}else{
lam[s] = old
accept=c(accept,0)
}
old = beta
beta = beta + rnorm(1,mean=0,sd=0.1)
prop = 0
if(beta > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop){
current.ll = propose.ll
}else{
beta = old
}
}
time.squiggle  = cutoff.time
censor.squiggle = cutoff.censor
beta
lam
beta
time.squiggle  = cutoff.time
censor.squiggle = cutoff.censor
for(s in on.study.id)
{
a.time = cutoff.time[s]
while(a.time <= cutoff.time[s])
{
a.time = rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
}
a.time = a.time - cutoff.time[s]
censor.squiggle[s] = ifelse(a.time < data.cutoff, 1, 0)
time.squiggle[s] = time.squiggle[s] + min(data.cutoff,a.time)
}
fit<-survfit(Surv(time.squiggle,censor.squiggle)~data$new_trt)
t = fit[1]$time
s = fit[1]$surv
t
s
plot(s)
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*sample-1),length(s)))
trt_group <-c(trt_group,rep(1,length(s)))
control.temp = t[which(s <= 0.5)[1]]
control.median[sample] = control.temp
control.events[sample] = sum(censor.squiggle[data$new_trt==0])
t = fit[2]$time
s = fit[2]$surv
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*sample),length(s)))
trt_group <-c(trt_group,rep(2,length(s)))
s
plot(s)
fit[1]
fit[2]
time_vals<-c(time_vals,t)
time_vals
surv_vals<-c(surv_vals,s)
surv_vals
class <- c(class,rep((2*sample),length(s)))
trt_group <-c(trt_group,rep(2,length(s)))
geom_step(aes(x=t,y=s),data=as.data.frame(cbind(t,s)),color="green")
out_graph+geom_step(aes(x=t,y=s),data=as.data.frame(cbind(t,s)),color="green")
treat.temp = t[which(s <= 0.5)[1]]
treat.median[sample] = treat.temp
treat.events[sample] = sum(censor.squiggle[data$new_trt==1])
d = coxph(Surv(time.squiggle,censor.squiggle)~data$new_trt)
pvalue[sample] = summary(d)$coefficients[5]
hazardratio[sample] = exp(as.numeric(d[1]))
events[sample] = sum(censor.squiggle)
lower.bound[sample] = exp(as.numeric(d[1]) - 1.96*sqrt(as.numeric(d[2])))
upper.bound[sample] = exp(as.numeric(d[1]) + 1.96*sqrt(as.numeric(d[2])))
upper.bound
lower.bound
d
pvalue[sample] = summary(d)$coefficients[5]
hazardratio[sample] = exp(as.numeric(d[1]))
events[sample] = sum(censor.squiggle)
lower.bound[sample] = exp(as.numeric(d[1]) - 1.96*sqrt(as.numeric(d[2])))
upper.bound[sample] = exp(as.numeric(d[1]) + 1.96*sqrt(as.numeric(d[2])))
for(sample in 1:nsamples)
{
message(paste("Running sample number",sample,"of",nsamples))
level = ifelse(sample==1,1000,500)
for(i in 1:level)
{
s = sample(c(1:length(lam)),1)
old = lam[s]
lam[s] = lam[s] + rnorm(1,mean=0,sd=0.05)
prop = 0
if(lam[s] > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop)
{
current.ll = propose.ll
accept = c(accept,1)
}else{
lam[s] = old
accept=c(accept,0)
}
old = beta
beta = beta + rnorm(1,mean=0,sd=0.1)
prop = 0
if(beta > 0){
#propose.ll = log.likelihood(cutoff.time,cutoff.censor,lam,beta,times,diff,data$new_trt)
propose.ll = log.likelihood_new(temp_mat,lam,beta,times,diff)
#print(propose.ll-propose.ll2)
prop = exp(propose.ll - current.ll)
}
if(runif(1) < prop){
current.ll = propose.ll
}else{
beta = old
}
}
time.squiggle  = cutoff.time
censor.squiggle = cutoff.censor
for(s in on.study.id)
{
a.time = cutoff.time[s]
while(a.time <= cutoff.time[s])
{
a.time = rpexp(1,rate=lam*exp(beta*data$new_trt[s]),c(0,times))
}
a.time = a.time - cutoff.time[s]
censor.squiggle[s] = ifelse(a.time < data.cutoff, 1, 0)
time.squiggle[s] = time.squiggle[s] + min(data.cutoff,a.time)
}
fit<-survfit(Surv(time.squiggle,censor.squiggle)~data$new_trt)
t = fit[1]$time
s = fit[1]$surv
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*sample-1),length(s)))
trt_group <-c(trt_group,rep(1,length(s)))
control.temp = t[which(s <= 0.5)[1]]
control.median[sample] = control.temp
control.events[sample] = sum(censor.squiggle[data$new_trt==0])
t = fit[2]$time
s = fit[2]$surv
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*sample),length(s)))
trt_group <-c(trt_group,rep(2,length(s)))
# out_graph <- out_graph+geom_step(aes(x=t,y=s),data=as.data.frame(cbind(t,s)),color="green")
treat.temp = t[which(s <= 0.5)[1]]
treat.median[sample] = treat.temp
treat.events[sample] = sum(censor.squiggle[data$new_trt==1])
d = coxph(Surv(time.squiggle,censor.squiggle)~data$new_trt)
pvalue[sample] = summary(d)$coefficients[5]
hazardratio[sample] = exp(as.numeric(d[1]))
events[sample] = sum(censor.squiggle)
lower.bound[sample] = exp(as.numeric(d[1]) - 1.96*sqrt(as.numeric(d[2])))
upper.bound[sample] = exp(as.numeric(d[1]) + 1.96*sqrt(as.numeric(d[2])))
}
lower.bound
upper.bound
fit <- survfit(Surv(data[[value]],data[[cnsr]])~data$new_trt)
t = fit[1]$time
s = fit[1]$surv
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*nsamples+1),length(s)))
trt_group <-c(trt_group,rep(3,length(s)))
t = fit[2]$time
s = fit[2]$surv
time_vals<-c(time_vals,t)
surv_vals<-c(surv_vals,s)
class <- c(class,rep((2*nsamples+2),length(s)))
trt_group <-c(trt_group,rep(3,length(s)))
out <- list(time_vals,surv_vals,class,trt_group,lower.bound,upper.bound,control.median,treat.median,
pvalue,hazardratio,events,treat.events,control.events)
out
data$new_trt[s]
s
s=1
data$new_trt[s]
lam
lam*exp(beta*data$new_trt[s])
c(0,times)
